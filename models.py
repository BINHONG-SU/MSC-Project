import numpy as np
import warnings
warnings.filterwarnings('ignore')
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import MultinomialNB
from keras import optimizers, initializers
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout
from sklearn.metrics import confusion_matrix,  accuracy_score, auc, roc_curve
#############################################################################
class models:

    def __init__(self):
        return None

    def LR(self, X_train, Y_train, X_test, Y_test):
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        tuned_parameters = {'penalty': ['l1', 'l2'],
                            'C': [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]}
        model = LogisticRegression()
        grid = GridSearchCV(model, tuned_parameters, cv=5)
        grid.fit(X_train, Y_train)
        Y_pred = grid.predict(X_test)
        #print(grid.best_estimator_)
        print('Classifer_LR Accuracy:',accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))
        return accuracy_score(Y_test, Y_pred)




    def SVM(self,X_train, Y_train, X_test, Y_test):
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        tuned_parameters = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': np.logspace(-8, 0, 9, endpoint=True,base=2)}  # Set the hyperparameters need to be trained
        model = SVC(kernel='rbf', max_iter=10000)
        grid = GridSearchCV(model, tuned_parameters,cv=3)  # Use SVM with rbf kernel and 4-Fold Cross validation, consider all hyperparameter combinations
        grid.fit(X_train, Y_train)
        Y_pred = grid.predict(X_test)
        print('Classifer_SVM Accuracy:', accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))
        return accuracy_score(Y_test, Y_pred)


    def RF(self, X_train, Y_train, X_test, Y_test):
        tuned_parameters = {'n_estimators': [10, 50, 100, 200, 500]}
        model = RandomForestClassifier()
        grid = GridSearchCV(model, tuned_parameters, cv=3)
        grid = grid.fit(X_train, Y_train)
        Y_pred = grid.predict(X_test)
        print('Classifer_RF Accuracy:', accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))
        return accuracy_score(Y_test, Y_pred)



    def KNN(self, X_train, Y_train, X_test, Y_test):
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        tuned_parameters = {'n_neighbors': [10, 15, 20, 30, 50, 100]}  # ,200,300]}
        model = KNeighborsClassifier()
        grid = GridSearchCV(model, tuned_parameters, cv=3)
        grid = grid.fit(X_train, Y_train)
        Y_pred = grid.predict(X_test)
        print('Classifer_KNN Accuracy:', accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))
        return accuracy_score(Y_test, Y_pred)



    def NB(self, X_train, Y_train, X_test, Y_test):
        gnb = MultinomialNB()
        Y_pred = gnb.fit(X_train, Y_train).predict(X_test)
        print('Classifer_NB Accuracy:', accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))
        return accuracy_score(Y_test, Y_pred)


    def NN_age5559_male(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32, kernel_initializer= initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer= initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer= initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
    # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age55-59_male')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age5559_female(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32, kernel_initializer= initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer= initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer= initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
    # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age55-59_female')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age6064_male(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age60-64_male')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age6064_female(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age60-64_female')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age6569_male(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age65-69_male')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age6569_female(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age65-69_female')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age7074_male(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age70-74_male')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))


    def NN_age7074_female(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age70-74_female')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age7579_male(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age75-79_male')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age7579_female(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=80, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age75-79_female')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age8084_male(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=100, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age80-84_male')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))


    def NN_age8084_female(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=100, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age80-84_female')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))


    def NN_age8589_male(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age85-89_male')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age8589_female(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=100, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age85-89_female')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))


    def NN_age9098_male(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=150, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age90-98_male')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))

    def NN_age9098_female(self, X_train, Y_train, X_test, Y_test):
        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train = scaler.transform(X_train)
        X_test = scaler.transform(X_test)
        X_val = scaler.transform(X_val)
        model = Sequential()
        model.add(Dense(units=32, input_dim=32,
                            kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=15, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('relu'))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.5, seed=0)))
        model.add(Activation('sigmoid'))
        adam = optimizers.adam(lr=0.0003)
        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])
        history = model.fit(X_train, Y_train, batch_size=128, epochs=200, validation_data=(X_val, Y_val))
            # Summarize history for loss, plot loss curve
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('NN Model loss for age90-98_female')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'validation'], loc='upper right')
        plt.show()
        print(model.evaluate(X_test, Y_test, batch_size=32))
        Y_pred = model.predict_classes(X_test)
        print(accuracy_score(Y_test, Y_pred))
        print(confusion_matrix(Y_test, Y_pred))
        fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)
        print("AUC:", auc(fpr, tpr))